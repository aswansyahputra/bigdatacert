{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px 5px 50px 5px;\">\n",
    "    <img src=\"image/image.png\" style=\"width: 30%; float: right;\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center; inter-word;\"> \n",
    "    <h1 style=\"font-size: 50px;color:#4480C4\"> Data Mining Model-Structured Data</h1> \n",
    "</div>\n",
    "\n",
    "<div> \n",
    "    <h2 style=\"font-size: 20px;color:#ffce00; padding: 0px 0px 15px 0px; text-align: center\" >Big Data Analyst International Certification, Telkom University </h2> \n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: justify; text-justify: inter-word;\"> \n",
    "    <b>Overview:</b> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Regression Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:18px;color:#ffce00\">Multiple Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/winequality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates','alcohol']].values\n",
    "y = dataset['quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "seabornInstance.distplot(dataset['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df1 = df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Prasyarat\n",
    "# 1. Terdistribusi Normal\n",
    "# 2. Simpangan \n",
    "# 3. Multicollineritas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "\n",
    "# Import Data .csv\n",
    "df_csv = pd.read_csv('dataset/churn_new.csv', sep=',',)\n",
    "column_names = df_csv.columns.tolist()\n",
    "\n",
    "# Show 10 first Row\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"Unnamed:O\" Coloumn\n",
    "df = df_csv.drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Data Infomation\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the Feature, by remove the unused feature \n",
    "feature = ['Churn']\n",
    "train_feature = df.drop(feature, axis=1)\n",
    "\n",
    "# Set The Target\n",
    "train_target = df[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Feature\n",
    "train_feature.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_feature ,train_target, shuffle = True, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the training data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit The Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "# Predict To X_test\n",
    "y_predlg =logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrixlg = metrics.confusion_matrix(y_test, y_predlg)\n",
    "cnf_matrixlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Accuracy, Precision, Recall\n",
    "acc_lg = metrics.accuracy_score(y_test, y_predlg)\n",
    "prec_lg = metrics.precision_score(y_test, y_predlg)\n",
    "rec_lg = metrics.recall_score(y_test, y_predlg)\n",
    "\n",
    "print(\"Accuracy:\", acc_lg )\n",
    "print(\"Precision:\", prec_lg)\n",
    "print(\"Recall:\", rec_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation score\n",
    "cv_iterations = 10\n",
    "cv_score = cross_val_score(logreg, train_feature, train_target, cv=cv_iterations)\n",
    "print('Accuracy with cross-validation (split size = {}): {} (+/- {})'\n",
    "      .format(cv_iterations, round(cv_score.mean(),2), round(cv_score.std() * 2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Classification Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">Decision Tree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn import tree\n",
    "\n",
    "# Train Decision Tree\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Predict to Test Data \n",
    "y_preddtc = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Confussion Matrix\n",
    "cnf_matrixdtc = metrics.confusion_matrix(y_test, y_predlg)\n",
    "cnf_matrixdtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Accuracy, Precision, Recall\n",
    "acc_dtc = metrics.accuracy_score(y_test, y_preddtc)\n",
    "prec_dtc = metrics.precision_score(y_test, y_preddtc)\n",
    "rec_dtc = metrics.recall_score(y_test, y_preddtc)\n",
    "\n",
    "print(\"Accuracy:\", acc_dtc )\n",
    "print(\"Precision:\", prec_dtc)\n",
    "print(\"Recall:\", rec_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation score\n",
    "cv_iterations = 10\n",
    "cv_score = cross_val_score(dtc, train_feature, train_target, cv=cv_iterations)\n",
    "print('Accuracy with cross-validation (split size = {}): {} (+/- {})'\n",
    "      .format(cv_iterations, round(cv_score.mean(),2), round(cv_score.std() * 2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">k-Nearest Neighbor (k-NN)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penjelasan sedikit mengenai k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict to test data\n",
    "y_predknn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Confussion Matrix\n",
    "cnf_matrixknn = metrics.confusion_matrix(y_test, y_predknn)\n",
    "cnf_matrixknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Accuracy, Precision, Recall\n",
    "acc_knn = metrics.accuracy_score(y_test, y_predknn)\n",
    "prec_knn = metrics.precision_score(y_test, y_predknn)\n",
    "rec_knn = metrics.recall_score(y_test, y_predknn)\n",
    "\n",
    "print(\"Accuracy:\", acc_knn)\n",
    "print(\"Precision:\", prec_knn)\n",
    "print(\"Recall:\", rec_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation score\n",
    "cv_iterations = 10\n",
    "cv_score = cross_val_score(knn, train_feature, train_target, cv=cv_iterations)\n",
    "print('Accuracy with cross-validation (split size = {}): {} (+/- {})'\n",
    "      .format(cv_iterations, round(cv_score.mean(),2), round(cv_score.std() * 2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "#Train Naive Bayes Model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_predgnb= gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Confussion Matrix\n",
    "cnf_matrixgnb = metrics.confusion_matrix(y_test, y_predknn)\n",
    "cnf_matrixgnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Accuracy, Precision, Recall\n",
    "acc_gnb = metrics.accuracy_score(y_test, y_predknn)\n",
    "prec_gnb = metrics.precision_score(y_test, y_predknn)\n",
    "rec_gnb = metrics.recall_score(y_test, y_predknn)\n",
    "\n",
    "print(\"Accuracy:\", acc_gnb)\n",
    "print(\"Precision:\", prec_gnb)\n",
    "print(\"Recall:\", rec_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation score\n",
    "cv_iterations = 10\n",
    "cv_score = cross_val_score(gnb, train_feature, train_target, cv=cv_iterations)\n",
    "print('Accuracy with cross-validation (split size = {}): {} (+/- {})'\n",
    "      .format(cv_iterations, round(cv_score.mean(),2), round(cv_score.std() * 2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">Model Comparison</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree Accuracy =\",acc_dtc)\n",
    "print(\"k-NN Accuracy =\", acc_knn)\n",
    "print(\"Naive Bayes Accuracy =\", acc_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Clustering Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">K-Means Clustering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot styling\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "dataset = pd.read_csv('Dataset/clustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 Rows of Dataset\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show lenght of Dataset\n",
    "len(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics Descriptive\n",
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the data\n",
    "plot_income = sns.distplot(dataset[\"INCOME\"])\n",
    "plot_spend = sns.distplot(dataset[\"SPEND\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the values to understand the spread\n",
    "Income = dataset['INCOME'].values\n",
    "Spend = dataset['SPEND'].values\n",
    "X = np.array(list(zip(Income, Spend)))\n",
    "plt.scatter(Income, Spend, c='black', s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "    km=KMeans(n_clusters=i,init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    km.fit(X)\n",
    "    wcss.append(km.inertia_)\n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('wcss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Silhoutte\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "for n_cluster in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model with K-Means\n",
    "km2=KMeans(n_clusters=2,init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "y_means = km2.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the clusters for k=2\n",
    "plt.scatter(X[y_means==0,0],X[y_means==0,1],s=50, c='purple',label='Cluster1')\n",
    "plt.scatter(X[y_means==1,0],X[y_means==1,1],s=50, c='blue',label='Cluster2')\n",
    "\n",
    "\n",
    "plt.scatter(km2.cluster_centers_[:,0], km2.cluster_centers_[:,1],s=200,marker='s', c='red', alpha=0.7, label='Centroids')\n",
    "plt.title('Customer segments')\n",
    "plt.xlabel('Annual income')\n",
    "plt.ylabel('Annual spend')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">Hierarchical Clustering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the dendrogram to find the optimal number of clusters\n",
    "import scipy.cluster.hierarchy as sch\n",
    "dend=sch.dendrogram(sch.linkage(X, method='ward'))\n",
    "plt.title(\"Dendrogram\")\n",
    "plt.xlabel('Customer')\n",
    "plt.ylabel('euclidean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Hierarchical Clustering to the dataset\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "hc=AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward' )\n",
    "y_hc = hc.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the clusters\n",
    "plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
    "plt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
    "plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
    "# plt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n",
    "# plt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n",
    "# plt.scatter(X[y_hc == 5, 0], X[y_hc == 5, 1], s = 100, c = 'orange', label = 'Cluster 6')\n",
    "\n",
    "plt.title('Clusters of customers')\n",
    "plt.xlabel('Annual Income')\n",
    "plt.ylabel('Annual spend')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">Association Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size:1,5em;color:#ffce00\">Apriori</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "retail_df = pd.read_excel(\"Dataset/Online Retail.xlsx\")\n",
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove additional spaces\n",
    "retail_df['Description'] = retail_df['Description'].str.strip()\n",
    "\n",
    "# Remove NA values\n",
    "retail_df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
    "\n",
    "# Remove cancelled orders\n",
    "retail_df['InvoiceNo'] = retail_df['InvoiceNo'].astype('str')\n",
    "retail_df = retail_df[~retail_df['InvoiceNo'].str.contains('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Encode Function\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "def create_basket(country_filter):\n",
    "    basket = (retail_df[retail_df['Country'] == country_filter]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "    return basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_filter = \"France\"\n",
    "basket_french = create_basket(\"France\")\n",
    "basket_sets = basket_french.applymap(encode_units)\n",
    "basket_sets.drop('POSTAGE', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(basket_sets, min_support=0.05, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "rules.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
